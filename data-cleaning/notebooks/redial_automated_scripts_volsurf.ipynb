{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, glob, tqdm, pickle, joblib,json, shutil\n",
    "import re,time,argparse,logging, tempfile\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import rdkit.Chem\n",
    "import rdkit.Chem.AllChem\n",
    "import rdkit.Chem.MolStandardize\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity\n",
    "from collections import OrderedDict\n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.Chem import MolStandardize\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.rdMolDescriptors import CalcMolFormula\n",
    "from rdkit.Chem import SmilesMolSupplier, SDMolSupplier, SDWriter, SmilesWriter, MolStandardize, MolToSmiles, MolFromSmiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new data work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_necessary_dirs():\n",
    "    dirs_list = ['../data_main', '../data_volsurf', '../data_main/data_new_stand', \\\n",
    "                 '../data_main/data_new_models', \\\n",
    "                 '../data_main/data_stand_cleaned_new', \\\n",
    "                '../data_main/data_new_split_stand', '../scalers', \\\n",
    "                '../rdk_descriptors', '../data_main/added_new_data/', \\\n",
    "                '../volsurf_descriptors', '../data_volsurf/data_new_split_stand_volsurf', \\\n",
    "                '../data_volsurf/data_new_stand_volsurf/', '../data_volsurf/data_stand_cleaned_new_volsurf', \\\n",
    "                '../data_volsurf/data_new_models_volsurf']\n",
    "    for _dir in dirs_list:\n",
    "        if not os.path.isdir(_dir):\n",
    "            os.mkdir(_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_necessary_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New approach resolves chiral issue\n",
    "def Standardize(stdzr, remove_isomerism, molReader, molWriter):\n",
    "    n_mol=0; \n",
    "    for mol in molReader:\n",
    "        n_mol+=1\n",
    "        molname = mol.GetProp('_Name') if mol.HasProp('_Name') else ''\n",
    "        logging.debug('%d. %s:'%(n_mol, molname))\n",
    "        mol2 = StdMol(stdzr, mol, remove_isomerism)\n",
    "        output = rdkit.Chem.MolToSmiles(mol2, isomericSmiles=True) if mol2 else None\n",
    "        return output\n",
    "#############################################################################\n",
    "def MyNorms():\n",
    "    norms = list(MolStandardize.normalize.NORMALIZATIONS)\n",
    "    for i in range(len(norms)-1, 0, -1):\n",
    "        norm = norms[i]\n",
    "        if norm.name == \"Sulfoxide to -S+(O-)-\":\n",
    "            del(norms[i])\n",
    "    norms.append(MolStandardize.normalize.Normalization(\"[S+]-[O-] to S=O\",\n",
    "    \"[S+:1]([O-:2])>>[S+0:1](=[O-0:2])\"))\n",
    "    logging.info(\"Normalizations: {}\".format(len(norms)))\n",
    "    return(norms)\n",
    "\n",
    "#############################################################################\n",
    "def MyStandardizer(norms):\n",
    "    stdzr = MolStandardize.Standardizer(\n",
    "        normalizations = norms,\n",
    "        max_restarts = MolStandardize.normalize.MAX_RESTARTS,\n",
    "        prefer_organic = MolStandardize.fragment.PREFER_ORGANIC,\n",
    "        acid_base_pairs = MolStandardize.charge.ACID_BASE_PAIRS,\n",
    "        charge_corrections = MolStandardize.charge.CHARGE_CORRECTIONS,\n",
    "        tautomer_transforms = MolStandardize.tautomer.TAUTOMER_TRANSFORMS,\n",
    "        tautomer_scores = MolStandardize.tautomer.TAUTOMER_SCORES,\n",
    "        max_tautomers = MolStandardize.tautomer.MAX_TAUTOMERS\n",
    "        )\n",
    "    return(stdzr)\n",
    "\n",
    "#############################################################################\n",
    "def StdMol(stdzr, mol, remove_isomerism=False):\n",
    "    smi = MolToSmiles(mol, isomericSmiles=(not remove_isomerism)) if mol else None\n",
    "    mol_std = stdzr.standardize(mol) if mol else None\n",
    "    smi_std = MolToSmiles(mol_std, isomericSmiles=(not remove_isomerism)) if mol_std else None\n",
    "    logging.debug(f\"{smi:>28s} >> {smi_std}\")\n",
    "    return(mol_std)\n",
    "\n",
    "#############################################################################\n",
    "def preprocess_smi(smi):\n",
    "    norms = MolStandardize.normalize.NORMALIZATIONS\n",
    "\n",
    "    test_smiles = [smi]\n",
    "    test_label = [1] # dummy list\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    df = pd.DataFrame(zip(test_smiles, test_label), columns=['SMILES', 'Label'])\n",
    "\n",
    "    df.to_csv(temp_dir+'/temp_file.csv', index=False)\n",
    "\n",
    "    try:\n",
    "        molReader = SmilesMolSupplier(temp_dir+'/temp_file.csv', delimiter=',', smilesColumn=0, nameColumn=1, titleLine=True, sanitize=True)\n",
    "\n",
    "        molWriter = SmilesWriter(temp_dir+'/temp_outfile.csv', delimiter=',', nameHeader='Name',\n",
    "        includeHeader=True, isomericSmiles = (True), kekuleSmiles=False)\n",
    "        stdzr = MyStandardizer(norms)\n",
    "        stand_smiles = Standardize(stdzr, True, molReader, molWriter)\n",
    "        shutil.rmtree(temp_dir)\n",
    "        \n",
    "        return stand_smiles\n",
    "    except:\n",
    "        return '' \n",
    "def standardize_smiles(data_stand_dir, data_type):\n",
    "    if not os.path.isdir(data_stand_dir):\n",
    "        os.mkdir(data_stand_dir)\n",
    "        print('Directory for standard_smiles is created!')\n",
    "    def clean_smiles(df):\n",
    "        smiles = df['SMILES'].to_list()\n",
    "        smiles_stand = []\n",
    "        count_none = 0\n",
    "\n",
    "        for i in tqdm(range(len(smiles))):\n",
    "            smi_stand = preprocess_smi(smiles[i])\n",
    "            if smi_stand == '':\n",
    "                count_none+=1\n",
    "            smiles_stand.append(smi_stand)\n",
    "\n",
    "        df.insert(2, 'SMILES_stand', smiles_stand)\n",
    "        df['SMILES_stand'].replace('', np.nan, inplace=True)\n",
    "        # Before\n",
    "        df_before = df\n",
    "        df.dropna(subset=['SMILES_stand'], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        # After\n",
    "        print(f\"Total NaN removed {len(df_before)-len(df)}\")\n",
    "        print('Total number of unique Standard smiles', len(set(df['SMILES_stand'].tolist())))\n",
    "        print('SMILES_stand not found: ', count_none)\n",
    "        return df\n",
    "    \n",
    "    _file = '../ncats_data_v2/NCATS-HTS_mined20200921.xlsx'\n",
    "    _file2 = '../ncats_data_v2/NCATS-HTS_mined20200921_volsurf.csv'\n",
    "    if data_type == 'new':\n",
    "        df = pd.read_excel(open(_file, 'rb'), sheet_name = 'default')\n",
    "        filename,_ = os.path.splitext(os.path.basename(_file))\n",
    "    else:\n",
    "        df = pd.read_csv(_file2)\n",
    "        filename,_ = os.path.splitext(os.path.basename(_file2))\n",
    "    clean_df = clean_smiles(df)\n",
    "    clean_df.to_csv(os.path.join(data_stand_dir, filename+'_stand.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize_smiles('../data_main/data_new_stand/', 'new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gvin/miniconda3/envs/redial-2020-latest/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3337: DtypeWarning: Columns (4,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      " 24%|██▍       | 2544/10532 [00:13<00:58, 135.77it/s]RDKit ERROR: [09:46:14] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:46:14] ERROR: Could not sanitize molecule on line 1\n",
      "RDKit ERROR: [09:46:14] ERROR: Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:46:14] Explicit valence for atom # 21 O, 3, is greater than permitted\n",
      "RDKit ERROR: [09:46:14] ERROR: Could not sanitize molecule on line 1\n",
      "RDKit ERROR: [09:46:14] ERROR: Explicit valence for atom # 21 O, 3, is greater than permitted\n",
      "RDKit ERROR: [09:46:14] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:46:14] ERROR: Could not sanitize molecule on line 1\n",
      "RDKit ERROR: [09:46:14] ERROR: Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:46:14] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:46:14] ERROR: Could not sanitize molecule on line 1\n",
      " 24%|██▍       | 2571/10532 [00:14<01:32, 85.95it/s] RDKit ERROR: [09:46:14] ERROR: Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:46:15] Explicit valence for atom # 15 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:46:15] ERROR: Could not sanitize molecule on line 1\n",
      "RDKit ERROR: [09:46:15] ERROR: Explicit valence for atom # 15 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:46:15] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:46:15] ERROR: Could not sanitize molecule on line 1\n",
      " 99%|█████████▉| 10455/10532 [01:04<00:00, 197.83it/s]RDKit ERROR: [09:46:15] ERROR: Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "RDKit ERROR: [09:47:05] Can't kekulize mol.  Unkekulized atoms: 3 10\n",
      "RDKit ERROR: \n",
      "100%|██████████| 10532/10532 [01:05<00:00, 161.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN removed 0\n",
      "Total number of unique Standard smiles 10520\n",
      "SMILES_stand not found:  6\n"
     ]
    }
   ],
   "source": [
    "standardize_smiles('../data_volsurf/data_new_stand_volsurf/', 'volsurf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phys_chem_filters(data_standard_file, activity, data_stand_cleaned):# data here is standardized data\n",
    "    print('Remove \"nan\" from activity column')\n",
    "    data = pd.read_csv(data_standard_file, low_memory=False)\n",
    "    temp = data\n",
    "    data = data[data[activity]!=np.nan]\n",
    "    temp2 = data # For the case when no filters are used\n",
    "    data.dropna(subset = [activity], inplace =True)\n",
    "    print(f\"'nan' removed {len(temp)-len(data)}\")\n",
    "    data_hm_before = data[data[activity].isin(['HIGH', 'MODERATE'])]\n",
    "    data_l_before = data[data[activity].isin(['LOW'])]\n",
    "    print(f'Total number of actives and inactives before filters:\\\n",
    "        {len(data_hm_before)}, {len(data_l_before)}')\n",
    "#     use_filters_list = ['CPE.ACTIVITY','cytotox.ACTIVITY','AlphaLISA.ACTIVITY','TruHit.ACTIVITY']\n",
    "#     not_use_filters_list = ['CoV1-PPE.ACTIVITY','CoV1-PPE_cs.ACTIVITY',\\\n",
    "#                                      'MERS-PPE.ACTIVITY','MERS-PPE_cs.ACTIVITY',\\\n",
    "#                                      'hCYTOX.ACTIVITY','ACE2.ACTIVITY','3CL.ACTIVITY']\n",
    "#         if activity_type in use_filters_list:\n",
    "    data_filt = data[(data['logPow {predicted by ochem.eu/model/535 in Log unit}']>=1) \\\n",
    "          & (data['logPow {predicted by ochem.eu/model/535 in Log unit}']<=9) \\\n",
    "         & (data['Aqueous Solubility {predicted by ochem.eu/model/536 in log(mol/L)}']<=-3) \\\n",
    "         &(data['Aqueous Solubility {predicted by ochem.eu/model/536 in log(mol/L)}']>=-7.5)] \n",
    "#         else:\n",
    "#             data_filt = data\n",
    "    data_hm_after = data_filt[data_filt[activity].isin(['HIGH', 'MODERATE'])]\n",
    "    data_l_after = data_filt[data_filt[activity].isin(['LOW'])]\n",
    "    print(f'Total number of actives and inactives after filters:\\\n",
    "        {len(data_hm_after)}, {len(data_l_after)}')\n",
    "    removed_actives = 100*((len(data_hm_before)-len(data_hm_after))/len(data_hm_before))\n",
    "    removed_inactives = 100*((len(data_l_before)-len(data_l_after))/len(data_l_before))\n",
    "    print(f'Removed actives %: {removed_actives}')\n",
    "    print(f'Removed inactives %: {removed_inactives}')\n",
    "#     if activity in not_use_filters_list:\n",
    "    if removed_actives >15.0:\n",
    "        # Do not use filters\n",
    "        print('Filters not used')\n",
    "        data_filt = temp2\n",
    "    else:\n",
    "        print('Filters used')\n",
    "        \n",
    "    data_filt_before = len(data_filt)\n",
    "    data_filt = data_filt[data_filt[activity.split('.')[0]+'.SIGNIFICANCE']!='INCONCLUSIVE']\n",
    "    data_filt_after = len(data_filt)\n",
    "    print(f'INCONCLUSIVE removed {data_filt_before - data_filt_after}')\n",
    "    # Label the data\n",
    "    data_filt.insert(len(data_filt.columns), 'Label', ['ACTIVE' if \\\n",
    "                                            i=='HIGH' or i=='MODERATE' else 'INACTIVE' \\\n",
    "                                             for i in data_filt[activity].to_list()])\n",
    "    data_filt.sort_values(by = 'Label', ascending = True)\n",
    "    data_filt = data_filt.drop_duplicates(subset='SMILES_stand', keep=\"first\") # , inplace=True removed\n",
    "    if not os.path.isdir(data_stand_cleaned):\n",
    "        os.mkdir(data_stand_cleaned)\n",
    "    # will be saved in data_stand_cleaned (given, eg: data_old_models (5), data_new_models (10))\n",
    "    data_filt.to_csv(data_stand_cleaned+'/'+activity.split('.')[0]+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Working with============= CoV1-PPE.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 7899\n",
      "Total number of actives and inactives before filters:        906, 1721\n",
      "Total number of actives and inactives after filters:        659, 840\n",
      "Removed actives %: 27.262693156732894\n",
      "Removed inactives %: 51.19116792562464\n",
      "Filters not used\n",
      "INCONCLUSIVE removed 30\n",
      "==========Working with============= CoV1-PPE_cs.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 7899\n",
      "Total number of actives and inactives before filters:        160, 2467\n",
      "Total number of actives and inactives after filters:        117, 1382\n",
      "Removed actives %: 26.875\n",
      "Removed inactives %: 43.980543169841916\n",
      "Filters not used\n",
      "INCONCLUSIVE removed 5\n",
      "==========Working with============= MERS-PPE.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 7899\n",
      "Total number of actives and inactives before filters:        535, 2092\n",
      "Total number of actives and inactives after filters:        431, 1068\n",
      "Removed actives %: 19.439252336448597\n",
      "Removed inactives %: 48.94837476099426\n",
      "Filters not used\n",
      "INCONCLUSIVE removed 53\n",
      "==========Working with============= MERS-PPE_cs.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 7899\n",
      "Total number of actives and inactives before filters:        193, 2434\n",
      "Total number of actives and inactives after filters:        147, 1352\n",
      "Removed actives %: 23.83419689119171\n",
      "Removed inactives %: 44.45357436318817\n",
      "Filters not used\n",
      "INCONCLUSIVE removed 14\n",
      "==========Working with============= hCYTOX.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 6734\n",
      "Total number of actives and inactives before filters:        379, 3413\n",
      "Total number of actives and inactives after filters:        298, 2107\n",
      "Removed actives %: 21.372031662269126\n",
      "Removed inactives %: 38.2654556108995\n",
      "Filters not used\n",
      "INCONCLUSIVE removed 0\n",
      "==========Working with============= ACE2.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 7441\n",
      "Total number of actives and inactives before filters:        187, 2898\n",
      "Total number of actives and inactives after filters:        117, 1706\n",
      "Removed actives %: 37.4331550802139\n",
      "Removed inactives %: 41.13181504485852\n",
      "Filters not used\n",
      "INCONCLUSIVE removed 24\n",
      "==========Working with============= 3CL.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 1182\n",
      "Total number of actives and inactives before filters:        290, 9054\n",
      "Total number of actives and inactives after filters:        209, 5724\n",
      "Removed actives %: 27.93103448275862\n",
      "Removed inactives %: 36.779324055666\n",
      "Filters not used\n",
      "INCONCLUSIVE removed 1\n",
      "==========Working with============= CPE.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 2066\n",
      "Total number of actives and inactives before filters:        539, 7921\n",
      "Total number of actives and inactives after filters:        495, 5008\n",
      "Removed actives %: 8.16326530612245\n",
      "Removed inactives %: 36.77565963893448\n",
      "Filters used\n",
      "INCONCLUSIVE removed 7\n",
      "==========Working with============= cytotox.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 2066\n",
      "Total number of actives and inactives before filters:        1376, 7084\n",
      "Total number of actives and inactives after filters:        1183, 4320\n",
      "Removed actives %: 14.026162790697674\n",
      "Removed inactives %: 39.01750423489554\n",
      "Filters used\n",
      "INCONCLUSIVE removed 63\n",
      "==========Working with============= AlphaLISA.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 7441\n",
      "Total number of actives and inactives before filters:        778, 2307\n",
      "Total number of actives and inactives after filters:        635, 1188\n",
      "Removed actives %: 18.380462724935732\n",
      "Removed inactives %: 48.50455136540962\n",
      "Filters not used\n",
      "INCONCLUSIVE removed 0\n",
      "==========Working with============= TruHit.ACTIVITY\n",
      "Remove \"nan\" from activity column\n",
      "'nan' removed 7441\n",
      "Total number of actives and inactives before filters:        839, 2246\n",
      "Total number of actives and inactives after filters:        705, 1118\n",
      "Removed actives %: 15.971394517282478\n",
      "Removed inactives %: 50.22261798753339\n",
      "Filters not used\n",
      "INCONCLUSIVE removed 0\n"
     ]
    }
   ],
   "source": [
    "activity_list_new = ['CoV1-PPE.ACTIVITY','CoV1-PPE_cs.ACTIVITY',\\\n",
    "                                 'MERS-PPE.ACTIVITY','MERS-PPE_cs.ACTIVITY',\\\n",
    "                                 'hCYTOX.ACTIVITY','ACE2.ACTIVITY','3CL.ACTIVITY',\\\n",
    "                       'CPE.ACTIVITY','cytotox.ACTIVITY','AlphaLISA.ACTIVITY','TruHit.ACTIVITY']\n",
    "for activity in activity_list_new:\n",
    "    print('==========Working with=============', activity)\n",
    "    phys_chem_filters('../data_volsurf/data_new_stand_volsurf/NCATS-HTS_mined20200921_volsurf_stand.csv', activity, '../data_volsurf/data_stand_cleaned_new_volsurf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data():\n",
    "    def balance_and_split(update_data):\n",
    "        df2 = pd.read_csv(update_data, low_memory=False)\n",
    "        df2_positive_only = df2[df2['Label']=='ACTIVE']\n",
    "        df2_negative_only = df2[~df2['SMILES_stand'].isin(df2_positive_only['SMILES_stand'].to_list())]\n",
    "        df2_negative_reduced = df2_negative_only.sample(n=len(df2_positive_only), random_state=42) \n",
    "        df_balanced = pd.concat([df2_positive_only, df2_negative_reduced])\n",
    "        df_balanced.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        x = df_balanced.iloc[:,:-1].values\n",
    "        y = df_balanced.iloc[:,-1].values\n",
    "        val=test=0.15\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.15, random_state=42, stratify=y)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,test_size=\\\n",
    "                                        (round((val/(1-test)), 3)),random_state=42, stratify = y_train)\n",
    "        # Resize y for concatenation\n",
    "        y_train = y_train.reshape(len(y_train),1)\n",
    "        y_val = y_val.reshape(len(y_val),1)\n",
    "        y_test = y_test.reshape(len(y_test),1)\n",
    "        print(os.path.basename(update_data), len(y_train), len(y_val), len(y_test))\n",
    "        # Conctenation\n",
    "        tr = np.concatenate((x_train, y_train), axis=1)\n",
    "        va = np.concatenate((x_val, y_val), axis=1)\n",
    "        te = np.concatenate((x_test, y_test), axis=1)\n",
    "\n",
    "        df_new = [tr,va,te]\n",
    "        return df_new\n",
    "\n",
    "    for _file in glob.glob('../data_volsurf/data_stand_cleaned_new_volsurf/*.csv'):\n",
    "        d,_ = os.path.splitext(os.path.basename(_file))\n",
    "        temp_df = pd.read_csv(_file, low_memory=False)\n",
    "        # Select necessary columns only\n",
    "        # Get train, validation, and test split of new files \n",
    "        new_split = balance_and_split(_file)\n",
    "        \n",
    "        splits = ['tr', 'va', 'te']\n",
    "        # Change Label names ACTIVE, INACTIVE to 1 and 0 resp.\n",
    "        if not os.path.isdir('../data_volsurf/data_new_models_volsurf/'+d):\n",
    "            os.mkdir('../data_volsurf/data_new_models_volsurf/'+d)\n",
    "        \n",
    "        for s, n in zip(splits, new_split):\n",
    "            pd.DataFrame(n).to_csv('../data_volsurf/data_new_split_stand_volsurf/'+\\\n",
    "                   d+ \"-balanced_randomsplit7_70_15_15\"+\"_\"+ s +\".csv\",\\\n",
    "                   header = list(temp_df.columns), index=False)\n",
    "            df_n = pd.read_csv('../data_volsurf/data_new_split_stand_volsurf/'+\\\n",
    "                               d+ \"-balanced_randomsplit7_70_15_15\"+\"_\"+ s +\".csv\", low_memory=False)\n",
    "            df_n[\"Label\"].replace({\"ACTIVE\": 1, \"INACTIVE\": 0}, inplace=True)\n",
    "            df_n = df_n.loc[:, ~df_n.columns.str.contains('^Unnamed')]\n",
    "            df_n.to_csv('../data_volsurf/data_new_models_volsurf'+'/'+d+'/'+\\\n",
    "                               d+ \"-balanced_randomsplit7_70_15_15\"+\"_\"+ s +\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaLISA.csv 1089 233 234\n",
      "cytotox.csv 1569 336 337\n",
      "ACE2.csv 228 49 49\n",
      "CoV1-PPE.csv 1226 263 263\n",
      "TruHit.csv 1175 251 252\n",
      "MERS-PPE_cs.csv 250 54 54\n",
      "MERS-PPE.csv 674 145 145\n",
      "CoV1-PPE_cs.csv 216 47 47\n",
      "3CL.csv 404 87 87\n",
      "hCYTOX.csv 530 114 114\n",
      "CPE.csv 691 148 149\n"
     ]
    }
   ],
   "source": [
    "update_data() # using filters (only two (before I used for 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get rdkit Descriptors Scalers for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdk_features(data_folder):\n",
    "    def rdk_descriptors(csvFile):\n",
    "        calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in Descriptors._descList])\n",
    "        fpdict ={}\n",
    "        fpdict['rdkDes'] = lambda m: calc.CalcDescriptors(m)\n",
    "        df = pd.read_csv(csvFile)\n",
    "        stand_smi = df['SMILES_stand'].tolist()\n",
    "        rdkit_des = []\n",
    "        \n",
    "        def CalculateFP(fp_name, smiles):\n",
    "            m = Chem.MolFromSmiles(smiles)\n",
    "            return fpdict[fp_name](m)\n",
    "        for i in range(len(stand_smi)):\n",
    "            fp = CalculateFP('rdkDes', stand_smi[i])\n",
    "            fp = np.asarray(fp)\n",
    "            fp = fp.reshape(1,200)\n",
    "            rdkit_des.append(fp)\n",
    "        X = np.array(rdkit_des)\n",
    "        X = X.reshape(len(rdkit_des),200)\n",
    "        df = pd.DataFrame.from_records(X)\n",
    "        print(df.isnull().sum().sum())\n",
    "        for col in df.columns:\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        X = df.iloc[:,0:].values\n",
    "        X = np.vstack(X).astype(np.float32)\n",
    "        scaler = MinMaxScaler()\n",
    "        X = np.nan_to_num(X) # For 'inf' or '-inf' values. replaces by large num.\n",
    "        X = scaler.fit_transform(X)\n",
    "        return scaler\n",
    "    for d in os.listdir(data_folder):\n",
    "        for f in glob.glob(data_folder+'/'+d+'/*.csv'):\n",
    "            if f.endswith('_tr.csv'):\n",
    "                scaler = rdk_descriptors(f)\n",
    "                pickle.dump(scaler, open('../scalers/'+d+'-rdkDes_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "rdk_features('../data_volsurf/data_new_models_volsurf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def volsurf_scaler(data_folder):\n",
    "    def volsurf_descriptors(csvFile):\n",
    "        df = pd.read_csv(csvFile)\n",
    "        descriptors = df.iloc[:, 33:-1] # Give value of i where vs descriptors start.\n",
    "        scaler = MinMaxScaler()\n",
    "        X = scaler.fit_transform(descriptors)\n",
    "        return scaler\n",
    "    for d in os.listdir(data_folder):\n",
    "        for f in glob.glob(data_folder+'/'+d+'/*.csv'):\n",
    "            if f.endswith('_tr.csv'):\n",
    "                scaler = volsurf_descriptors(f)\n",
    "                pickle.dump(scaler, open('../scalers/'+d+'-volsurf_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "volsurf_scaler('../data_volsurf/data_new_models_volsurf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rdkDescriptors using saved Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rdk_features(data_folder):\n",
    "    calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in Descriptors._descList])\n",
    "    fpdict ={}\n",
    "    fpdict['rdkDes'] = lambda m: calc.CalcDescriptors(m)\n",
    "\n",
    "    def CalculateFP(fp_name, smiles):\n",
    "        m = Chem.MolFromSmiles(smiles)\n",
    "        return fpdict[fp_name](m)\n",
    "\n",
    "    for d in os.listdir(data_folder):\n",
    "        if d=='.DS_Store':\n",
    "            continue\n",
    "        pos = []\n",
    "        trg = []\n",
    "        for csv in glob.glob(data_folder\\\n",
    "                             +'/'+d+'/*.csv'):\n",
    "            des = []\n",
    "            not_found = []\n",
    "            df = pd.read_csv(csv)\n",
    "            clean_smi = df['SMILES_stand'].tolist()\n",
    "            rdkit_des = []\n",
    "            \n",
    "            for i in range(len(clean_smi)):\n",
    "                fp = CalculateFP('rdkDes', clean_smi[i])\n",
    "                fp = np.asarray(fp)\n",
    "                fp = fp.reshape(1,200)\n",
    "                rdkit_des.append(fp)\n",
    "\n",
    "            X = np.array(rdkit_des)\n",
    "            X = X.reshape(len(rdkit_des),200)\n",
    "            ndf = pd.DataFrame.from_records(X)\n",
    "            ndf.isnull().sum().sum()\n",
    "            r, _ = np.where(df.isna())\n",
    "            ndf.isnull().sum().sum()\n",
    "\n",
    "            for col in ndf.columns:\n",
    "                ndf[col].fillna(ndf[col].mean(), inplace=True)\n",
    "            ndf.isnull().sum().sum() \n",
    "            \n",
    "            X = ndf.iloc[:, 0:].values\n",
    "            X = np.vstack(X).astype(np.float32)\n",
    "            load_scaler = pickle.load(open('../scalers/'+d+'-'+'rdkDes_scaler.pkl', 'rb'))\n",
    "            X = np.nan_to_num(X) #np.nan_to_num(X) \"replace nan with zero and inf with finite numbers\"\n",
    "            X = load_scaler.transform(X)\n",
    "#             labelencoder = LabelEncoder()                       #Converting 'str' label to numeric label\n",
    "#             Y = labelencoder.fit_transform(df['Label'].values) \n",
    "            Y = df['Label'].values\n",
    "            Y = Y.reshape(Y.shape[0], 1)\n",
    "\n",
    "            fp_array = ( np.asarray((X), dtype=object) ) # Do i need this line\n",
    "            X = np.delete(fp_array, not_found, axis=0)\n",
    "            X = X.astype(np.float32) \n",
    "            print(fp_array.shape)\n",
    "            final_array = np.concatenate((X, Y), axis=1)\n",
    "            out = os.path.splitext(os.path.basename(csv))[0]\n",
    "            print(out,'---',final_array.shape)\n",
    "            pos.append(np.count_nonzero(Y))\n",
    "            trg.append(out)\n",
    "            print('pos',pos[-1])\n",
    "            np.save('../rdk_descriptors/'+\\\n",
    "                    'rdkDes-'+out+'.npy', np.asarray((final_array), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 200)\n",
      "MERS-PPE_cs-balanced_randomsplit7_70_15_15_tr --- (250, 201)\n",
      "pos 125\n",
      "(54, 200)\n",
      "MERS-PPE_cs-balanced_randomsplit7_70_15_15_te --- (54, 201)\n",
      "pos 27\n",
      "(54, 200)\n",
      "MERS-PPE_cs-balanced_randomsplit7_70_15_15_va --- (54, 201)\n",
      "pos 27\n",
      "(216, 200)\n",
      "CoV1-PPE_cs-balanced_randomsplit7_70_15_15_tr --- (216, 201)\n",
      "pos 108\n",
      "(47, 200)\n",
      "CoV1-PPE_cs-balanced_randomsplit7_70_15_15_te --- (47, 201)\n",
      "pos 24\n",
      "(47, 200)\n",
      "CoV1-PPE_cs-balanced_randomsplit7_70_15_15_va --- (47, 201)\n",
      "pos 23\n",
      "(87, 200)\n",
      "3CL-balanced_randomsplit7_70_15_15_va --- (87, 201)\n",
      "pos 43\n",
      "(404, 200)\n",
      "3CL-balanced_randomsplit7_70_15_15_tr --- (404, 201)\n",
      "pos 202\n",
      "(87, 200)\n",
      "3CL-balanced_randomsplit7_70_15_15_te --- (87, 201)\n",
      "pos 44\n",
      "(336, 200)\n",
      "cytotox-balanced_randomsplit7_70_15_15_va --- (336, 201)\n",
      "pos 168\n",
      "(337, 200)\n",
      "cytotox-balanced_randomsplit7_70_15_15_te --- (337, 201)\n",
      "pos 169\n",
      "(1569, 200)\n",
      "cytotox-balanced_randomsplit7_70_15_15_tr --- (1569, 201)\n",
      "pos 784\n",
      "(691, 200)\n",
      "CPE-balanced_randomsplit7_70_15_15_tr --- (691, 201)\n",
      "pos 345\n",
      "(149, 200)\n",
      "CPE-balanced_randomsplit7_70_15_15_te --- (149, 201)\n",
      "pos 75\n",
      "(148, 200)\n",
      "CPE-balanced_randomsplit7_70_15_15_va --- (148, 201)\n",
      "pos 74\n",
      "(233, 200)\n",
      "AlphaLISA-balanced_randomsplit7_70_15_15_va --- (233, 201)\n",
      "pos 117\n",
      "(1089, 200)\n",
      "AlphaLISA-balanced_randomsplit7_70_15_15_tr --- (1089, 201)\n",
      "pos 544\n",
      "(234, 200)\n",
      "AlphaLISA-balanced_randomsplit7_70_15_15_te --- (234, 201)\n",
      "pos 117\n",
      "(263, 200)\n",
      "CoV1-PPE-balanced_randomsplit7_70_15_15_va --- (263, 201)\n",
      "pos 131\n",
      "(1226, 200)\n",
      "CoV1-PPE-balanced_randomsplit7_70_15_15_tr --- (1226, 201)\n",
      "pos 613\n",
      "(263, 200)\n",
      "CoV1-PPE-balanced_randomsplit7_70_15_15_te --- (263, 201)\n",
      "pos 132\n",
      "(1175, 200)\n",
      "TruHit-balanced_randomsplit7_70_15_15_tr --- (1175, 201)\n",
      "pos 587\n",
      "(252, 200)\n",
      "TruHit-balanced_randomsplit7_70_15_15_te --- (252, 201)\n",
      "pos 126\n",
      "(251, 200)\n",
      "TruHit-balanced_randomsplit7_70_15_15_va --- (251, 201)\n",
      "pos 126\n",
      "(145, 200)\n",
      "MERS-PPE-balanced_randomsplit7_70_15_15_va --- (145, 201)\n",
      "pos 72\n",
      "(145, 200)\n",
      "MERS-PPE-balanced_randomsplit7_70_15_15_te --- (145, 201)\n",
      "pos 73\n",
      "(674, 200)\n",
      "MERS-PPE-balanced_randomsplit7_70_15_15_tr --- (674, 201)\n",
      "pos 337\n",
      "(49, 200)\n",
      "ACE2-balanced_randomsplit7_70_15_15_te --- (49, 201)\n",
      "pos 25\n",
      "(228, 200)\n",
      "ACE2-balanced_randomsplit7_70_15_15_tr --- (228, 201)\n",
      "pos 114\n",
      "(49, 200)\n",
      "ACE2-balanced_randomsplit7_70_15_15_va --- (49, 201)\n",
      "pos 24\n",
      "(530, 200)\n",
      "hCYTOX-balanced_randomsplit7_70_15_15_tr --- (530, 201)\n",
      "pos 265\n",
      "(114, 200)\n",
      "hCYTOX-balanced_randomsplit7_70_15_15_te --- (114, 201)\n",
      "pos 57\n",
      "(114, 200)\n",
      "hCYTOX-balanced_randomsplit7_70_15_15_va --- (114, 201)\n",
      "pos 57\n"
     ]
    }
   ],
   "source": [
    "get_rdk_features('../data_volsurf/data_new_models_volsurf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 200)\n",
      "3cl_external_set_stand --- (6, 201)\n",
      "pos 6\n",
      "(24, 200)\n",
      "cpe_external_set_after_phys-chem-filters_stand --- (24, 201)\n",
      "pos 24\n"
     ]
    }
   ],
   "source": [
    "get_rdk_features('../data_volsurf/externals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volsurf_descriptors(data_folder):\n",
    "    for d in os.listdir(data_folder):\n",
    "        if d=='.DS_Store':\n",
    "            continue\n",
    "        pos = []\n",
    "        trg = []\n",
    "        for csv in glob.glob(data_folder\\\n",
    "                             +'/'+d+'/*.csv'):\n",
    "            des = []\n",
    "            not_found = []\n",
    "            df = pd.read_csv(csv)\n",
    "            values = df.iloc[:, 33:-1]\n",
    "            load_scaler = pickle.load(open('../scalers/'+d+'-'+'volsurf_scaler.pkl', 'rb'))\n",
    "            X = load_scaler.transform(values)\n",
    "            Y = df['Label'].values\n",
    "            Y = Y.reshape(Y.shape[0],1)\n",
    "    #         fp_array = ( np.asarray((X), dtype=object) )\n",
    "    #         X = np.delete(fp_array, not_found, axis=0)\n",
    "            X = X.astype(np.float32) \n",
    "            final_array = np.concatenate((X, Y), axis=1)\n",
    "            out = os.path.splitext(os.path.basename(csv))[0]\n",
    "            print(out,'---',final_array.shape)\n",
    "            pos.append(np.count_nonzero(Y))\n",
    "            trg.append(out)\n",
    "            print('pos',pos[-1])\n",
    "            np.save('../volsurf_descriptors/'+\\\n",
    "                    'volsurf-'+out+'.npy', np.asarray((final_array), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERS-PPE_cs-balanced_randomsplit7_70_15_15_tr --- (250, 129)\n",
      "pos 125\n",
      "MERS-PPE_cs-balanced_randomsplit7_70_15_15_te --- (54, 129)\n",
      "pos 27\n",
      "MERS-PPE_cs-balanced_randomsplit7_70_15_15_va --- (54, 129)\n",
      "pos 27\n",
      "CoV1-PPE_cs-balanced_randomsplit7_70_15_15_tr --- (216, 129)\n",
      "pos 108\n",
      "CoV1-PPE_cs-balanced_randomsplit7_70_15_15_te --- (47, 129)\n",
      "pos 24\n",
      "CoV1-PPE_cs-balanced_randomsplit7_70_15_15_va --- (47, 129)\n",
      "pos 23\n",
      "3CL-balanced_randomsplit7_70_15_15_va --- (87, 129)\n",
      "pos 43\n",
      "3CL-balanced_randomsplit7_70_15_15_tr --- (404, 129)\n",
      "pos 202\n",
      "3CL-balanced_randomsplit7_70_15_15_te --- (87, 129)\n",
      "pos 44\n",
      "cytotox-balanced_randomsplit7_70_15_15_va --- (336, 129)\n",
      "pos 168\n",
      "cytotox-balanced_randomsplit7_70_15_15_te --- (337, 129)\n",
      "pos 169\n",
      "cytotox-balanced_randomsplit7_70_15_15_tr --- (1569, 129)\n",
      "pos 784\n",
      "CPE-balanced_randomsplit7_70_15_15_tr --- (691, 129)\n",
      "pos 345\n",
      "CPE-balanced_randomsplit7_70_15_15_te --- (149, 129)\n",
      "pos 75\n",
      "CPE-balanced_randomsplit7_70_15_15_va --- (148, 129)\n",
      "pos 74\n",
      "AlphaLISA-balanced_randomsplit7_70_15_15_va --- (233, 129)\n",
      "pos 117\n",
      "AlphaLISA-balanced_randomsplit7_70_15_15_tr --- (1089, 129)\n",
      "pos 544\n",
      "AlphaLISA-balanced_randomsplit7_70_15_15_te --- (234, 129)\n",
      "pos 117\n",
      "CoV1-PPE-balanced_randomsplit7_70_15_15_va --- (263, 129)\n",
      "pos 131\n",
      "CoV1-PPE-balanced_randomsplit7_70_15_15_tr --- (1226, 129)\n",
      "pos 613\n",
      "CoV1-PPE-balanced_randomsplit7_70_15_15_te --- (263, 129)\n",
      "pos 132\n",
      "TruHit-balanced_randomsplit7_70_15_15_tr --- (1175, 129)\n",
      "pos 587\n",
      "TruHit-balanced_randomsplit7_70_15_15_te --- (252, 129)\n",
      "pos 126\n",
      "TruHit-balanced_randomsplit7_70_15_15_va --- (251, 129)\n",
      "pos 126\n",
      "MERS-PPE-balanced_randomsplit7_70_15_15_va --- (145, 129)\n",
      "pos 72\n",
      "MERS-PPE-balanced_randomsplit7_70_15_15_te --- (145, 129)\n",
      "pos 73\n",
      "MERS-PPE-balanced_randomsplit7_70_15_15_tr --- (674, 129)\n",
      "pos 337\n",
      "ACE2-balanced_randomsplit7_70_15_15_te --- (49, 129)\n",
      "pos 25\n",
      "ACE2-balanced_randomsplit7_70_15_15_tr --- (228, 129)\n",
      "pos 114\n",
      "ACE2-balanced_randomsplit7_70_15_15_va --- (49, 129)\n",
      "pos 24\n",
      "hCYTOX-balanced_randomsplit7_70_15_15_tr --- (530, 129)\n",
      "pos 265\n",
      "hCYTOX-balanced_randomsplit7_70_15_15_te --- (114, 129)\n",
      "pos 57\n",
      "hCYTOX-balanced_randomsplit7_70_15_15_va --- (114, 129)\n",
      "pos 57\n"
     ]
    }
   ],
   "source": [
    "get_volsurf_descriptors('../data_volsurf/data_new_models_volsurf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volsurf_descriptors_ext(data_folder):\n",
    "    for d in os.listdir(data_folder):\n",
    "        if d=='.DS_Store':\n",
    "            continue\n",
    "        pos = []\n",
    "        trg = []\n",
    "        for csv in glob.glob(data_folder\\\n",
    "                             +'/'+d+'/*.csv'):\n",
    "            des = []\n",
    "            not_found = []\n",
    "            df = pd.read_csv(csv)\n",
    "            values = df.iloc[:, 3:-1]\n",
    "            load_scaler = pickle.load(open('../scalers/'+d+'-'+'volsurf_scaler.pkl', 'rb'))\n",
    "            X = load_scaler.transform(values)\n",
    "            Y = df['Label'].values\n",
    "            Y = Y.reshape(Y.shape[0],1)\n",
    "    #         fp_array = ( np.asarray((X), dtype=object) )\n",
    "    #         X = np.delete(fp_array, not_found, axis=0)\n",
    "            X = X.astype(np.float32) \n",
    "            final_array = np.concatenate((X, Y), axis=1)\n",
    "            out = os.path.splitext(os.path.basename(csv))[0]\n",
    "            print(out,'---',final_array.shape)\n",
    "            pos.append(np.count_nonzero(Y))\n",
    "            trg.append(out)\n",
    "            print('pos',pos[-1])\n",
    "            np.save('../volsurf_descriptors_ext/'+\\\n",
    "                    'volsurf-'+out+'.npy', np.asarray((final_array), dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3cl_external_set_stand --- (6, 129)\n",
      "pos 6\n",
      "cpe_external_set_after_phys-chem-filters_stand --- (24, 129)\n",
      "pos 24\n"
     ]
    }
   ],
   "source": [
    "get_volsurf_descriptors_ext('../data_volsurf/externals_volsurf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redial-2020-latest",
   "language": "python",
   "name": "redial-2020-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
